# ğŸ¤ Emotion Recognition from Speech using Deep Learning

This repository contains a deep learning pipeline for recognizing human emotions (e.g., happy, sad, angry) from raw audio speech. The model is trained on publicly available datasets and uses a combination of CNN and LSTM architectures to capture both local and sequential features of speech.

## ğŸš€ Project Overview

- **Goal:** Build a robust deep learning model that can classify emotions from speech audio using features like MFCCs.
- **Approach:** Deep learning with CNN + LSTM using extracted MFCCs, Delta & Delta-Delta features.
- **Datasets Used:** RAVDESS, TESS, EMO-DB (flexible to integrate)

## ğŸ“ Project Structure

â”œâ”€â”€ emotion_recognizer_dl_final.py # Training script

â”œâ”€â”€ inference_script_re_provide.py # Inference script for new audio prediction
â”œâ”€â”€ speech_emotion_dl_model.h5 # Saved Keras model
â”œâ”€â”€ label_encoder_dl.pkl # Saved label encoder for mapping predictions
â”œâ”€â”€ /RAVDESS # Dataset folder (not included)
â””â”€â”€ README.md # Project documentation

## ğŸ§  Features

- ğŸ“Œ **MFCCs + Deltas**: Extract Mel-Frequency Cepstral Coefficients (MFCC), Delta & Delta-Delta for richer representations
- ğŸ§± **Model Architecture**: Combines CNN (Conv1D, MaxPooling) and LSTM to learn temporal dependencies
- ğŸ’¾ **Model Saving**: Model is saved using `.h5`, and encoder via `joblib`
- ğŸ¯ **Inference Ready**: Inference script to test on unseen `.wav` audio files
- ğŸ“Š **Evaluation Metrics**: Accuracy, Precision, Recall, F1-Score via classification report

## ğŸ› ï¸ Tech Stack

- Python 3.9+
- TensorFlow / Keras
- Librosa
- Scikit-learn
- Pandas, NumPy, Matplotlib, Seaborn
- Joblib (for saving encoder)

## ğŸ“¦ How to Run

### ğŸ”¹ 1. Train the Model

```bash
python emotion_recognizer_dl_final.py


Make sure the dataset path in the script points to your local RAVDESS folder
Model and label encoder will be saved upon completion

ğŸ”¹ 2. Run Inference
bash
Copy
Edit
python inference_script_re_provide.py
Modify the script to test with your own .wav file

You will get a predicted emotion as output

ğŸ” Sample Output

ğŸ§ Input Audio: 03-01-05-01-01-01-01.wav
ğŸ¯ Predicted Emotion: Angry
ğŸ“Š Probabilities: {'Angry': 0.94, 'Happy': 0.03, 'Neutral': 0.02, 'Sad': 0.01}

ğŸ“š Dataset Reference

RAVDESS
TESS
EMO-DB

ğŸ™Œ Acknowledgements
This project leverages powerful speech processing libraries like Librosa and the capabilities of deep neural networks for audio understanding. Huge thanks to open-source contributors and dataset curators for enabling projects like this.


ğŸ’¡ Future Enhancements
Add support for noise filtering & audio augmentation
Extend to real-time emotion recognition using mic input
Build web app interface using Streamlit or Flask





